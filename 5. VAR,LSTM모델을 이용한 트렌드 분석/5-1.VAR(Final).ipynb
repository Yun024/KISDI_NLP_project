{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import LSTM\n",
    "from statsmodels.tsa.api import VAR\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "from math import log2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as pyo\n",
    "from datetime import datetime\n",
    "version_name=str(datetime.today().strftime(\"%Y%m%d\")) # 버전 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --trusted-host pypi.python.org --trusted-host files.pythonhosted.org --trusted-host pypi.org statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\newcomer02\\\\NTIS_Project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 토픽분포 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "토픽 개수를 입력하세요 :  20\n",
      "시작 년도를 입력하세요 :  2017\n",
      "데이터가 몇개년으로 이루어져 있는지 입력하세요: 5\n"
     ]
    }
   ],
   "source": [
    "topic_num=int(input(\"토픽 개수를 입력하세요 : \"))\n",
    "start_year=int(input(\"시작 년도를 입력하세요 : \"))\n",
    "year_length = int(input(\"데이터가 몇개년으로 이루어져 있는지 입력하세요:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "./data/prediction 내 사용할 데이터 폴더명을 입력하세요 (Default:엔터키):  REPORT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "REPORT 데이터의 토픽 분포를 예측합니다.\n"
     ]
    }
   ],
   "source": [
    "folder_name = input(\"./data/prediction 내 사용할 데이터 폴더명을 입력하세요 (Default:엔터키): \")\n",
    "path='./data/Default/'+folder_name+'/prediction/'+folder_name+'_topic_dist_'+str(topic_num)+'.pkl'    \n",
    "print(\"\\n%s 데이터의 토픽 분포를 예측합니다.\"%(folder_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence(p, q):\n",
    "    return sum(p[i] * log2(p[i]/q[i]) for i in range(len(p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 및 성능 평가\n",
    "# 추후, 년도가 추가 된다면 2018년 뒤에 2019, 2020, ...이 붙을 수 있지만, \n",
    "# word, labels, topic, 2014, 2015, ... 의 컬럼 순서는 유지 되어야 함\n",
    "\n",
    "def Real_Predict_Measure(path):\n",
    "    DATA = pd.read_pickle(path)\n",
    "    #del DATA['topic']\n",
    "    \n",
    "    Y_col = list(DATA[DATA.columns[len(DATA.columns)-1]])\n",
    "\n",
    "    dist_refined_valid=DATA.iloc[:,0:len(DATA.columns)-1].values\n",
    "\n",
    "    dist_refined_valid=dist_refined_valid.T.astype(float)\n",
    "\n",
    "    var_model_valid = VAR(endog=dist_refined_valid)\n",
    "\n",
    "    var_model_fit_valid = var_model_valid.fit(2)\n",
    "\n",
    "    new_dist_valid = var_model_fit_valid.forecast(var_model_valid.y, steps=1)\n",
    "\n",
    "    predict_last_year=new_dist_valid.tolist()[0]\n",
    "\n",
    "    DATA['predict_prob'] = predict_last_year\n",
    "\n",
    "    var_model_valid.y.tolist()\n",
    "\n",
    "    new_dist_valid.tolist()[0]\n",
    "\n",
    "    Y_test = list(new_dist_valid[0])\n",
    "    \n",
    "    mse = metrics.mean_squared_error(Y_col, Y_test)\n",
    "    r2 = metrics.r2_score(Y_col, Y_test)\n",
    "    kld = kl_divergence(Y_col, Y_test)\n",
    "    \n",
    "    return DATA, Y_col, Y_test, mse, r2, kld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 0.000161\n",
      "\n",
      "R-Square : 0.957953\n",
      "\n",
      "KL-Divergence : 0.061038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\newcomer02\\AppData\\Local\\Temp\\ipykernel_10856\\1902019045.py:19: FutureWarning:\n",
      "\n",
      "y is a deprecated alias for endog, will be removed in version 0.11.0\n",
      "\n",
      "C:\\Users\\newcomer02\\AppData\\Local\\Temp\\ipykernel_10856\\1902019045.py:25: FutureWarning:\n",
      "\n",
      "y is a deprecated alias for endog, will be removed in version 0.11.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DATA, Y_col, Y_test, mse, r2, kld = Real_Predict_Measure(path)\n",
    "#DATA, Y_col, Y_test, mse, r2 = Real_Predict_Measure(path)\n",
    "print(\"MSE : %f\"%(mse))\n",
    "print(\"\\nR-Square : %f\"%(r2))\n",
    "print(\"\\nKL-Divergence : %f\"%(kld))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA.columns= [0,1,2,3,4,\"predict_prob\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def All_Plot1(DATA, path):\n",
    "    \n",
    "    plt.style.use('default')\n",
    "    DIR = \"C:\\\\Users\\\\newcomer02\\\\NTIS_Project\\\\data\\\\Default\\\\NTIS\\\\LDA\\\\VAR,LSTM\\\\NKIS\\\\topic_distribution\\\\\"\n",
    "    top_list = []\n",
    "    for i in range(len(DATA)):\n",
    "        top_list.append('topic '+str(i+1))\n",
    "\n",
    "    top_pred_list = []\n",
    "    for i in top_list:\n",
    "        top_pred_list.append(i+' Pred')\n",
    "\n",
    "    new_df = pd.DataFrame()\n",
    "    for i in range(len(DATA)):\n",
    "        new_df['topic '+str(i+1)] = DATA.iloc[i]\n",
    "\n",
    "    year_list = []\n",
    "    for i in range(len(DATA.columns)-1):\n",
    "        year_list.append(start_year+i)\n",
    "\n",
    "    yr_topic_norm = []\n",
    "    for i in range(len(DATA.columns)-1):\n",
    "        yr_topic_norm.append(list(DATA[i]))\n",
    "\n",
    "    topic_dist_norm = []\n",
    "    for j in range(len(DATA)):\n",
    "        topic_yr = []\n",
    "        for i in range(len(DATA.columns)-1):\n",
    "            topic_yr.append(yr_topic_norm[i][j])\n",
    "        topic_dist_norm.append(topic_yr)\n",
    "\n",
    "    topic_sum = []\n",
    "    for i in topic_dist_norm:\n",
    "        c = 0\n",
    "        c+=sum(i)\n",
    "        topic_sum.append(c)\n",
    "\n",
    "    topic_sort = sorted(topic_sum, reverse=True)    \n",
    "\n",
    "    idx_sort = []\n",
    "    for i in topic_sort:\n",
    "        idx_sort.append(topic_sum.index(i))\n",
    "\n",
    "    top_id = []\n",
    "    for i in range(len(DATA)):\n",
    "        top_id.append(i+1)\n",
    "\n",
    "    index = np.arange(len(DATA))\n",
    "    bar_width = 0.35\n",
    "    plt.figure(figsize=(15,3))\n",
    "    p1 = plt.bar(index, Y_test, bar_width)\n",
    "    p2 = plt.bar(index+bar_width, Y_col, bar_width)\n",
    "    plt.title('VAR '+str(start_year+len(DATA.columns)-2)+' Topic Distribution')\n",
    "    plt.xlabel('Topic', fontsize=10)\n",
    "    plt.ylabel('Probability', fontsize=10)\n",
    "    plt.xticks(index, top_id, fontsize=10)\n",
    "    plt.legend((p1[0], p2[0]), ('Prediction', 'Real'), fontsize=10)\n",
    "    # plt.savefig(DIR+\"/All_Topics_Verification\")\n",
    "    plt.show()\n",
    "    \n",
    "    top_pred = []\n",
    "    for j in range(len(DATA)):\n",
    "        asdf = []\n",
    "        for i in range(len(DATA.columns)-2):\n",
    "            asdf.append(topic_dist_norm[j][i])\n",
    "        asdf.append(Y_test[j])\n",
    "        top_pred.append(asdf)\n",
    "\n",
    "    for i in range(len(DATA)):\n",
    "        plt.title('Topic ' + str(i+1) + '_var_Distribution')\n",
    "        plt.grid()\n",
    "        labels = top_list\n",
    "\n",
    "        plt.plot(year_list, top_pred[i], label = top_pred_list[i], linestyle = 'dotted')\n",
    "        p2 = plt.scatter(year_list, top_pred[i])\n",
    "        plt.plot(year_list, topic_dist_norm[i], label = top_list[i])\n",
    "        p1 = plt.scatter(year_list, topic_dist_norm[i])\n",
    "\n",
    "        plt.plot()\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.xticks(np.arange(start_year,start_year+len(DATA.columns)-1),labels = [i for i in list(range(start_year,start_year+len(DATA.columns)-1))])\n",
    "        plt.tick_params(axis='x', direction='in', length=3, pad=6, labelsize=14, top=True)\n",
    "        #plt.savefig(DIR + 'topic_' + str(i+1)+'_var')\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "All_Plot1(DATA, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def New_Predict_Measure(path,step):\n",
    "    DATA = pd.read_pickle(path)\n",
    "    #del DATA['topic']\n",
    "\n",
    "    dist_refined_valid=DATA.iloc[:,0:len(DATA.columns)].values\n",
    "    dist_refined_valid=dist_refined_valid.T.astype(float)\n",
    "    var_model_valid = VAR(endog=dist_refined_valid)\n",
    "    var_model_fit_valid = var_model_valid.fit(2)\n",
    "    len(var_model_valid.y.tolist())\n",
    "    new_dist_valid = var_model_fit_valid.forecast(var_model_valid.y, steps=step)\n",
    "    col = len(DATA.columns)\n",
    "    for i in range(step) :\n",
    "        predict_next_year=new_dist_valid.tolist()[i]\n",
    "        DATA[col+i] = predict_next_year\n",
    "\n",
    "    return DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = New_Predict_Measure(path,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "\n",
    "def All_Plot2(DATA,step):\n",
    "    #DIR = \"C:\\\\Users\\\\newcomer02\\\\NTIS_Project\\\\data\\\\Default\\\\NTIS\\\\LDA\\\\VAR,LSTM\\\\NKIS\\\\topic_prediction\\\\\"\n",
    "    top_list = []\n",
    "    for i in range(len(DATA)):\n",
    "        top_list.append('topic '+str(i+1))\n",
    "\n",
    "    top_pred_list = []\n",
    "    for i in top_list:\n",
    "        top_pred_list.append(i+' Pred')\n",
    "\n",
    "    new_df = pd.DataFrame()\n",
    "    for i in range(len(DATA)):\n",
    "        new_df['topic '+str(i+1)] = DATA.iloc[i]\n",
    "    \n",
    "    year_list = []\n",
    "    for i in range(len(DATA.columns)):\n",
    "        year_list.append(start_year+i)\n",
    "\n",
    "    yr_topic_norm = []\n",
    "    for i in range(len(DATA.columns)):\n",
    "        yr_topic_norm.append(list(DATA.iloc[:,i]))\n",
    "\n",
    "    topic_dist_norm = []\n",
    "    for j in range(len(DATA)):\n",
    "        topic_yr = []\n",
    "        for i in range(len(DATA.columns)-1):\n",
    "            topic_yr.append(yr_topic_norm[i][j])\n",
    "        topic_dist_norm.append(topic_yr)\n",
    "\n",
    "    topic_sum = []\n",
    "    for i in topic_dist_norm:\n",
    "        c = 0\n",
    "        c+=sum(i)\n",
    "        topic_sum.append(c)\n",
    "\n",
    "    topic_sort = sorted(topic_sum, reverse=True)    \n",
    "\n",
    "    idx_sort = []\n",
    "    for i in topic_sort:\n",
    "        idx_sort.append(topic_sum.index(i))\n",
    "\n",
    "    top_id = []\n",
    "    for i in range(len(DATA)):\n",
    "        top_id.append(i+1)\n",
    "\n",
    "    top_pred = []\n",
    "    for j in range(len(DATA)):\n",
    "        topic_yr = []\n",
    "        for i in range(len(DATA.columns)-1):\n",
    "            topic_yr.append(topic_dist_norm[j][i])\n",
    "        topic_yr.append(Y_test[j])\n",
    "        top_pred.append(topic_yr)\n",
    "    \n",
    "    for i in range(len(DATA)):\n",
    "        plt.title(folder_name+'_Topic ' + str(i+1) + '_var_Prediction')\n",
    "        #plt.grid()\n",
    "        labels = top_list\n",
    "\n",
    "        plt.plot(year_list, top_pred[i], label = top_pred_list[i], linestyle = 'dotted')\n",
    "        p2 = plt.scatter(year_list, top_pred[i])\n",
    "        plt.plot(year_list[:-step], topic_dist_norm[i][:-step+1], label = top_list[i])\n",
    "        p1 = plt.scatter(year_list[:-step], topic_dist_norm[i][:-step+1])\n",
    "\n",
    "        plt.plot()\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.xticks(np.arange(start_year,start_year+len(DATA.columns)),labels = [i for i in list(range(start_year,start_year+len(DATA.columns)))])\n",
    "        plt.tick_params(axis='x', direction='in', length=3, pad=6, labelsize=14, top=True)\n",
    "        #plt.savefig(DIR + 'topic_' + str(i+1) + '_var')\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "All_Plot2(DATA,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_LABEL = []\n",
    "for i in range(len(DATA)):\n",
    "    DATA_LABEL.append('topic'+str(i+1))\n",
    "    \n",
    "DATA['LABEL']=DATA_LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "SORTED_DATA=DATA.sort_values(by=[len(DATA.columns)-2],axis=0,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output type : ICT NTIS/NEWS 연도별 html 파일 (html/DTM 폴더)\n",
    "\n",
    "def ntis_time(DATA,top_n):\n",
    "    color=[ 'aqua', 'aquamarine','beige', 'bisque', 'black', 'blanchedalmond', 'blue',\n",
    "            'blueviolet', 'brown', 'burlywood', 'cadetblue',\n",
    "            'chartreuse', 'chocolate','coral', 'cornflowerblue',\n",
    "            'cornsilk', 'crimson', 'cyan', 'darkblue', 'darkcyan',\n",
    "            'darkgoldenrod', 'darkgray', 'darkgrey', 'darkgreen','darkkhaki', 'darkmagenta', 'darkolivegreen', 'darkorange',\n",
    "            'darkorchid', 'darkred', 'darksalmon', 'darkseagreen',\n",
    "            'darkslateblue', 'darkslategray', 'darkslategrey',\n",
    "            'darkturquoise', 'darkviolet', 'deeppink', 'deepskyblue',\n",
    "            'dimgray', 'dimgrey', 'dodgerblue', 'firebrick']\n",
    "    plot=[]\n",
    "    \n",
    "    for i in range(top_n):\n",
    "        plot.append(go.Scatter(x = np.array(range(2017,2017+len(DATA.columns)-4)), y = SORTED_DATA.iloc[i,:-2], line=dict(color=color[i],width=4),mode = 'lines+markers', name = SORTED_DATA.iloc[i,-1]))\n",
    "        plot.append(go.Scatter(x = np.array(range(2017,2017+len(DATA.columns)-3)), y = SORTED_DATA.iloc[i,:-1], line=dict(color=color[i],dash='dashdot',width=4),mode = 'lines+markers', name = 'predicted_'+SORTED_DATA.iloc[i,-1]))\n",
    "        \n",
    "\n",
    "    \n",
    "    layout = go.Layout(title='NTIS 토픽별 트렌드(VAR)',\n",
    "                       legend=dict(x=0,y=-1.7),margin=dict(l=20, r=20, t=60, b=300),paper_bgcolor=\"White\",\n",
    "                       autosize=True,title_font_size=30,font=dict(size=15),hoverlabel=dict(\n",
    "                                   \n",
    "        font_size=16,\n",
    "        font_family=\"Rockwell\"\n",
    "    ),\n",
    "                    xaxis=dict({\"tickvals\":list(range(2014,2014+len(DATA.columns))),\n",
    "                            \"ticktext\":[str(i) for i in list(range(2017,2017+len(DATA.columns)))],\n",
    "                           \"title\":\"연도\"}),\n",
    "                    yaxis=dict({\"title\":\"토픽 비중\"}))\n",
    "    \n",
    "    gen_ntis = go.Figure(data=plot, layout=layout)\n",
    "    pyo.iplot(gen_ntis)\n",
    "    \n",
    "    # gen_ntis.write_html(DIR+'/'+\"ntis_trace_상위\"+str(top_n)+\".html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntis_time(DATA,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 단어 분포 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "예측에 사용할 상위 단어 갯수를 지정하세요 (권장값=1000) :  1000\n"
     ]
    }
   ],
   "source": [
    "# input : pkl 파일, 없으면 에러 (data/PREDICTION 폴더)\n",
    "data=pd.read_pickle('./data/Default/'+folder_name+'/prediction/WORDS_'+ folder_name +\"_\"+ str(topic_num)+'.pkl')\n",
    "TOPN=int(input(\"예측에 사용할 상위 단어 갯수를 지정하세요 (권장값=1000) : \"))\n",
    "data=data[data.index<TOPN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - 존재하는 마지막 년도 예측\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_mode(data):\n",
    "    \n",
    "    topic_list = list(range(topic_num))\n",
    "    for y in tqdm(range(topic_num)):\n",
    "        ex_da=data[data['topic']==y+1]\n",
    "        if len(ex_da) > 1:\n",
    "            valid_da=ex_da.iloc[:,3:-1].values\n",
    "            valid_da=valid_da.T\n",
    "            var_model_valid = VAR(endog=valid_da)\n",
    "            var_model_fit_valid = var_model_valid.fit(1)\n",
    "            new_dist_valid = var_model_fit_valid.forecast(var_model_fit_valid.endog, steps=1)\n",
    "            name1='predict_var'+str(data.columns[-1])\n",
    "            ex_da[name1]=new_dist_valid.tolist()[0]\n",
    "            norm=[]\n",
    "            for i in ex_da[name1]:\n",
    "                if i <=0:\n",
    "                    norm.append(0)\n",
    "                else:\n",
    "                    norm.append(i)\n",
    "            ex_da[name1]=norm\n",
    "            if y==topic_list[0]:\n",
    "                final=ex_da\n",
    "            else:\n",
    "                final=pd.concat([final, ex_da])\n",
    "        else:\n",
    "            topic_list.pop(topic_list.index(y))\n",
    "    return final[final[\"predict_var2021\"]!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data 인풋 데이터, t 시퀀스, predict_year= 2018년도까지 데이터가 있다면,\n",
    "# 2018년도를 예측하게 해서 해당 데이터의 var성능을 평가\n",
    "\n",
    "first_df=var_mode(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Topic_Predict_Measure(fir_df):\n",
    "    for u in range(topic_num):\n",
    "        df=fir_df[fir_df[\"topic\"]==u+1]\n",
    "        if len(df)>0:\n",
    "            word_col = df.iloc[:,-2:-1]\n",
    "            word_col = word_col[word_col.columns[0]].tolist()\n",
    "            word_test = df.iloc[:,-1:]\n",
    "            word_test = word_test[word_test.columns[0]].tolist()\n",
    "\n",
    "            cond1 = list(filter(lambda x:word_test[x]==0, range(len(word_test))))\n",
    "            cond2 = list(filter(lambda x: word_col[x]==0, range(len(word_col))))\n",
    "            cond = cond1 +cond2\n",
    "            if len(cond) != 0:\n",
    "                j = 0\n",
    "                for k in cond:\n",
    "                    del word_test[k-j] \n",
    "                    del word_col[k-j] \n",
    "                    j +=1\n",
    "\n",
    "\n",
    "            mse = metrics.mean_squared_error(word_col, word_test)\n",
    "            r2 = metrics.r2_score(word_col, word_test)\n",
    "            kld = kl_divergence(word_col, word_test)\n",
    "\n",
    "            print(\"\\nTopic\"+ str(u+1))\n",
    "            print(\"MSE : %.8f\" %(mse))\n",
    "            print(\"R-Square: %f\"%(r2))\n",
    "            print(\"kL-Divergence : %f\"%(kld))\n",
    "\n",
    "Topic_Predict_Measure(first_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2018년도와 predict_18년도의 값을 비교하여 해당 데이터에 VAR성능이 어느 정도로 잘 나오는지 확인\n",
    "# 만약, Spearsman_corr 결과, 낮은 값들이 많다면 향후 년도 예측의 성능이 낮을 수 있음\n",
    "\n",
    "def spearsman_corr(fi_da):\n",
    "    topic_corr=[]\n",
    "    to_data=[]\n",
    "    year=fi_da.columns[-2]\n",
    "    predict_year=fi_da.columns[-1]\n",
    "    \n",
    "    for i in tqdm(range(1,topic_num+1)):\n",
    "        real=fi_da[fi_da['topic']==i][['word',year]]\n",
    "        if len(real) > 0:\n",
    "            real=real.sort_values(by=[year],ascending=False)\n",
    "            real['Number']=list(range(len(real)))\n",
    "            predict=fi_da[fi_da['topic']==i][['word',predict_year]]\n",
    "            predict=predict.sort_values(by=[predict_year],ascending=False)\n",
    "            predict['Number']=list(range(len(predict)))\n",
    "            predict.columns=['predict_word',predict_year,'predict_Number']\n",
    "            predict\n",
    "            for su in range(len(real)):\n",
    "                wo=list(real['word'])\n",
    "                data=predict[predict['predict_word']==wo[su]]\n",
    "                if su==0:\n",
    "                    fo=data\n",
    "                else:\n",
    "                    fo=pd.concat([fo,data])\n",
    "            fina=pd.concat([real,fo],axis=1)\n",
    "            to_data.append(fina)\n",
    "            topic_corr.append(fina[['Number','predict_Number']].corr(method='spearman').iloc[0,1])\n",
    "        \n",
    "    plt.figure(figsize=(25, 10))\n",
    "    to=pd.DataFrame(columns=['corr'])\n",
    "    \n",
    "    to['corr']=topic_corr\n",
    "    to.index=list(range(1,len(fi_da['topic'].unique())+1))\n",
    "    to['corr'].plot(kind='bar')\n",
    "    #to['corr'].sort_values(ascending=False).plot(kind='bar')\n",
    "    \n",
    "    plt.title('TOPIC')\n",
    "    plt.ylabel('spearsman_corr')\n",
    "    #plt.savefig(DIR+'/'+data_type+'_topic_' + str(i+1)+'_spearman correlaion')\n",
    "    return to_data,to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랭킹 변동 확인\n",
    "# 스피어만 상관계수의 범위는 -1 ~ 1 까지로, 비교적 높은 결과가 나옴 -> VAR로 향후 년도를 예측하는게 의미가 있다고 판단 \n",
    "\n",
    "da,to=spearsman_corr(first_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\newcomer02\\AppData\\Roaming\\Python\\Python38\\site-packages\\numpy\\core\\fromnumeric.py:3430: FutureWarning:\n",
      "\n",
      "In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "corr    0.394552\n",
       "dtype: float64"
      ]
     },
     "execution_count": 716,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 토픽 별 단어 미래 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "step = input(\"몇년 후 까지 예측하고 싶은지 입력하시오: \")\n",
    "def var_mode_next_year(data,step):\n",
    "    from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "    \n",
    "    topic_list = list(range(topic_num))\n",
    "    for y in tqdm(range(topic_num)):\n",
    "        ex_da=data[data['topic']==y+1]\n",
    "        if len(ex_da)>1: \n",
    "            valid_da=ex_da.iloc[:,3:].values\n",
    "            valid_da=valid_da.T\n",
    "            var_model_valid = VAR(endog=valid_da)\n",
    "            var_model_fit_valid = var_model_valid.fit(1)\n",
    "            new_dist_valid = var_model_fit_valid.forecast(var_model_fit_valid.endog, steps=step)\n",
    "\n",
    "            for i in range(step):\n",
    "                next_year='predict_var'+str(int(data.columns[-1])+(1+int(i)))\n",
    "                ex_da[next_year]=new_dist_valid.tolist()[i]\n",
    "                norm=[]\n",
    "                for k in ex_da[next_year]:\n",
    "                    if k <=0:\n",
    "                        norm.append(0)\n",
    "                    else:\n",
    "                        norm.append(k)\n",
    "                ex_da[next_year]=norm\n",
    "\n",
    "            if y==topic_list[0]:\n",
    "                final=ex_da\n",
    "            else:\n",
    "                final=pd.concat([final, ex_da])\n",
    "        else:\n",
    "            topic_list.pop(topic_list.index(y))\n",
    "    return final\n",
    "\n",
    "final_df=var_mode_next_year(data,int(step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic별 단어 미래 예측 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확인하고자 하는 topic 번호 및 상위 몇 개의 단어를 보고싶은지 설정하여 시각화\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "def topic_word_plot2(data,topic,top_N,step): \n",
    "    \n",
    "    DIR = \"C:\\\\Users\\\\newcomer02\\\\NTIS_Project\\\\data\\\\Default\\\\NTIS\\\\LDA\\\\VAR,LSTM\\\\NKIS\\\\topic_word_prediction_html\\\\\"\n",
    "    step = int(step)\n",
    "\n",
    "    obj_col = data.columns.tolist()[:3].copy()\n",
    "    num_col = []\n",
    "    for i in range(start_year,(start_year+year_length+step)):\n",
    "        num_col.append(i)\n",
    "    data.columns = obj_col + num_col\n",
    "    \n",
    "    df = data[data[\"topic\"]==topic].iloc[:top_N,:]\n",
    "    if len(df) > 0:\n",
    "        df = df.set_index(\"word\")\n",
    "        df = df.iloc[:,2:].T\n",
    "\n",
    "        ye = df.index.tolist()\n",
    "\n",
    "        col = list(df.columns)\n",
    "        color=['brown','red','darkviolet','deeppink','forestgreen', 'fuchsia','indigo','lawngreen', 'lightslategray','yellow','silver','skyblue','tomato', 'turquoise','yellowgreen','black','chocolate','darkgoldenrod']\n",
    "\n",
    "        plot=[]\n",
    "\n",
    "        for N in range(min(top_N,len(col))):\n",
    "            #기존의 데이터\n",
    "            plot.append(go.Scatter(y=list(df[col[N]].iloc[:-step]), x=ye[:-step],name=col[N],line=dict(color=color[N],width=2),marker = dict(symbol=\"cross\",color=color[N]),mode='lines+markers'))\n",
    "            plot.append(go.Scatter(y=list(df[col[N]].iloc[-step-1:]), x=ye[-step-1:],name=\"예측\"+str(col[N]),line=dict(color=color[N],dash=\"dashdot\",width=2),marker = dict(symbol=\"cross\",color=color[N]),mode='lines+markers'))\n",
    "\n",
    "        layout = go.Layout(title=data[data[\"topic\"]== topic][\"labels\"][0],autosize=True,\n",
    "                           xaxis=dict(\n",
    "                                tickvals=ye,\n",
    "                               title=\"연도\"),\n",
    "                           yaxis=dict(title = \"Topic내 단어 순위\",linewidth=4))\n",
    "\n",
    "        fig=go.Figure(data=plot,layout=layout)\n",
    "\n",
    "        plotly.offline.iplot({\n",
    "            \"data\": plot,\n",
    "            \"layout\": go.Layout(autosize=True,height=500,width=700,title=data[data[\"topic\"]== topic][\"labels\"][0],legend=dict(font=dict(size=15)),margin=dict(l=20, r=20,t=100),xaxis = dict(title = \"연도\",linewidth=0.5,\n",
    "                                tickvals=ye\n",
    "        ),yaxis=dict(title = \"Topic내 단어 순위\",linewidth=2))})#,auto_open=True,filename=DIR+\"topic_\"+str(topic)+\"_var.html\",image=\"png\",image_filename=\"topic_\" + str(topic) + \"_var\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(topic_num):\n",
    "    topic_word_plot2(final_df,i+1,5,step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_di(data,word,number_of_topics):\n",
    "   \n",
    "    length=len(data['topic'].unique())\n",
    "    ds=[]\n",
    "    fib=[]\n",
    "    ra=[]\n",
    "    \n",
    "    name=list(data.labels.unique())\n",
    "    for rank in tqdm(range(1,length+1)):\n",
    "        word_da=data[data['topic']==rank].iloc[0:,3:]     \n",
    "        \n",
    "        ye=list(word_da.columns[0:-2])\n",
    "        ye.append(str(int(word_da.columns[-3])+1))\n",
    "        \n",
    "        for i in range(len(word_da.columns)):\n",
    "            word_da.iloc[:,i:i+1]=word_da.iloc[:,i:i+1].rank(ascending=False) \n",
    "        word_da['word']=data[data['topic']==rank].iloc[0:,0:1]     \n",
    "\n",
    "        ran=list(word_da.iloc[:,-3:-2].sum(axis=1))\n",
    "        word_da['rank']=ran\n",
    "        word_da['rank']=word_da['rank'].rank(ascending=True) \n",
    "        word_da.sort_values(by=['rank'],axis=0,inplace=True)\n",
    "        word_da=word_da.reset_index().iloc[:,1:-1]\n",
    "        word_das=word_da.set_index('word').T\n",
    "        \n",
    "        ds.append(word_das)\n",
    "   \n",
    "    for nu,dd in enumerate(range(len(ds))):\n",
    "        if word in ds[dd].columns:\n",
    "            ra.append(nu)\n",
    "            fib.append(ds[dd])\n",
    "            \n",
    "    if len(fib)!=0:\n",
    "   \n",
    "        for su,dat in enumerate(fib):\n",
    "            if su==0:\n",
    "                dat=pd.DataFrame(dat[word])\n",
    "                dat.columns=[word+'--'+str(name[su-1])]\n",
    "                finalss=dat\n",
    "            else:\n",
    "                dat=pd.DataFrame(dat[word])\n",
    "                dat.columns=[word+'--'+str(name[su-1])]\n",
    "                finalss=pd.concat([finalss,dat],axis=1)\n",
    "\n",
    "\n",
    "        finalss=finalss.T.sort_values(by=data.columns[-5]).T\n",
    "        \n",
    "        print('찾을수있는 number_of_topics의 최대길이 :',len(finalss.columns))\n",
    "            #number_of_topics=len(finalss.columns)\n",
    "\n",
    "        color=['fuchsia','brown','darkgray','darkviolet','deeppink','forestgreen','indigo','lawngreen', 'lightslategray','silver','skyblue','tomato'', turquoise','yellow','yellowgreen']\n",
    "\n",
    "        plot=[]\n",
    "\n",
    "        for N in range(number_of_topics):\n",
    "            yy=[]\n",
    "            i=0\n",
    "            for ys in range(len(ye)-1):\n",
    "                yy.append(i)\n",
    "                i+=1    \n",
    "\n",
    "            plot.append(go.Scatter(y=list(finalss.iloc[0:len(yy),N]), x=ye[0:-1],name=str(list(finalss.columns)[N]),line=dict(color=color[N], width=4),marker = dict(color=color[N]),mode='lines+markers'))\n",
    "\n",
    "            fin=finalss.drop([data.columns[-3]])\n",
    "\n",
    "            plot.append(go.Scatter(y=list(fin.iloc[:,N]), x=ye,name='예측_'+word,line=dict(color=color[N],dash='dashdot',width=4),marker = dict(color=color[N]),mode ='lines+markers'))\n",
    "\n",
    "        plotly.offline.iplot({\n",
    "            \"data\": plot,\n",
    "            \"layout\": go.Layout(title=word, xaxis = dict(title = \"년도\",linewidth=0.5),\n",
    "\n",
    "        yaxis=dict(autorange='reversed',title = \"Topic별 단어 순위\",linewidth=2),legend=dict(\n",
    "        yanchor=\"top\",\n",
    "        y=-0.5,\n",
    "        xanchor=\"left\",\n",
    "        x=0\n",
    "    ))})\n",
    "\n",
    "        plotly.offline.init_notebook_mode(connected=False)\n",
    "\n",
    "        plotly.offline.plot({\n",
    "            \"data\": plot,\n",
    "            \"layout\": go.Layout(title=word,xaxis = dict(title = \"년도\",linewidth=0.5),\n",
    "\n",
    "        yaxis=dict(autorange='reversed',title = \"Topic내 해당 단어 순위\",linewidth=2),legend=dict(\n",
    "        yanchor=\"top\",\n",
    "        y=-0.5,\n",
    "        xanchor=\"left\",\n",
    "        x=0\n",
    "    ))}, auto_open=False)\n",
    "        \n",
    "    else:\n",
    "        print('해당 단어는 데이터에 존재하지 않습니다.')\n",
    "\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_word=input(\"분석하고자 하는 단어를 입력하세요 : \")\n",
    "max_length = 2\n",
    "try:\n",
    "    topic_di(data=final_df,word=target_word,number_of_topics=max_length)\n",
    "except IndexError:\n",
    "    max_length -=1\n",
    "    topic_di(data=final_df,word=target_word,number_of_topics=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df.to_excel(\"C:\\\\Users\\\\KISDI\\\\연세대_FINAL\\\\html\\\\VAR\\\\KISAU_20210808\\\\var_43_ntis.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mecab",
   "language": "python",
   "name": "mecab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
