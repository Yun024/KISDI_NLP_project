{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaec117-15d5-4194-bff3-4537d372986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Load\n",
    "import pickle\n",
    "import pyLDAvis\n",
    "import math\n",
    "import copy\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import tomotopy as tp\n",
    "import tomotopy.coherence as tpc\n",
    "from gensim.corpora import Dictionary\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from timeit import default_timer\n",
    "import plotly.express as px\n",
    "import plotly.offline\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.offline as pyo\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "version_name=str(datetime.today().strftime(\"%Y%m%d\")) # 버전 정보 변수\n",
    "import os\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49a82d89-b614-4e7e-8adc-6dbb7f2256fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import operator\n",
    "import numpy as np\n",
    "import scipy\n",
    "import itertools\n",
    "import nltk\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib as mpl\n",
    "#pip install scipy networkx==2.6.3  # coo_array에러나면 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daebe1b5-cde3-408d-b29c-e27e7f3fa746",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\newcomer02\\\\NTIS_Project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d8bdde0-a94c-4fe2-b2f8-e785e70c6874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "사용자명을 설정해주세요(영어로만 설정해주세요) :  newcomer\n"
     ]
    }
   ],
   "source": [
    "user_name = input(\"사용자명을 설정해주세요(영어로만 설정해주세요) : \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb9fae5-88dd-4c84-8c32-9f036e561bcb",
   "metadata": {},
   "source": [
    "## Option1 : 기존에 학습된 모델을 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1461ee86-b625-4d74-987f-a0e50b231889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "불러올 DTM모델 명을 입력하세요 :  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Default DTM모델을 불러옵니다.\n"
     ]
    }
   ],
   "source": [
    "# input : model 폴더명, 없으면 오류 발생 (원하는 버전 모델 있으면 지정 필요, 없으면 Enter -> Default)\n",
    "# model 폴더 안에 bin파일, 없으면 오류 발생\n",
    "                                     \n",
    "dtm_ver=input(\"불러올 DTM모델 명을 입력하세요 : \")\n",
    "if dtm_ver=='':\n",
    "    print(\"\\nDefault DTM모델을 불러옵니다.\")\n",
    "    mdl=tp.DTModel.load(\"./model/DTM_model_41.bin\")\n",
    "else:\n",
    "    print(\"\\n기존에 학습된 %s모델을 불러옵니다.\"%(dtm_ver))\n",
    "    mdl=tp.DTModel.load(\"./model/\"+dtm_ver+\".bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61c5dd23-2f7f-4167-b5b6-d24b31faacb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "토픽 갯수 :  41\n",
      "NTIS 시작 연도 :  2017\n",
      "NTIS 최종 연도 :  2021\n"
     ]
    }
   ],
   "source": [
    "# 토픽수, 연도, 학습수 사용자 입력 \n",
    "\n",
    "num_topics=int(input(\"토픽 갯수 : \"))\n",
    "\n",
    "start_year = int(input(\"NTIS 시작 연도 : \"))\n",
    "\n",
    "num_time=int(input(\"NTIS 최종 연도 : \")) - start_year + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1befae1f-6165-4e27-88f3-75820ddf80c3",
   "metadata": {},
   "source": [
    "# 파일 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "515a12c3-5eff-48aa-8301-c29a9f4a20bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "사용할 데이터 폴더명을 입력하세요(Default: 엔터키):  \n"
     ]
    }
   ],
   "source": [
    "data_ver=input(\"사용할 데이터 폴더명을 입력하세요(Default: 엔터키): \")\n",
    "if data_ver=='':\n",
    "    DATA_DIR = './data/Default/NTIS/DTM/'\n",
    "else:\n",
    "    DATA_DIR = './data/DTM/'+data_ver+'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9883d3b1-eefd-4d8a-924e-388517b4ebc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "사용할 데이터 명을 입력하세요(Default: 엔터키):  DTM_HanModel_kisau_(NTIS_2021)20221021_0.5\n"
     ]
    }
   ],
   "source": [
    "dtm_txt=input(\"사용할 데이터 명을 입력하세요(Default: 엔터키): \")\n",
    "#DTM_HanModel_kisau_(NTIS_2021)20221021_0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbfc8ad0-3839-404c-9b36-a92abc547444",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76695it [00:10, 7552.72it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "코퍼스 파일 로드가 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# input : data/LDA 폴더에 txt 형태 코퍼스 파일, 없으면 오류 발생\n",
    "\n",
    "corpus=[]\n",
    "for n, line in tqdm(enumerate(open(DATA_DIR+dtm_txt+\".txt\", encoding='CP949'))):\n",
    "    doc=line.strip().split()\n",
    "    corpus.append(doc)\n",
    "print(\"코퍼스 파일 로드가 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85fba584-f822-4d1a-9bab-96e3b9466ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corpus Load Function\n",
    "\n",
    "def data_feeder(input_file):\n",
    "    for line in tqdm(open(input_file, encoding='CP949')):\n",
    "        fd = line.strip().split(maxsplit=1) \n",
    "        timepoint = int(fd[0])\n",
    "        if len(fd) == 1 : \n",
    "            continue \n",
    "\n",
    "        yield fd[1], None, {'timepoint':timepoint}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "963fa7fb-4777-4899-b540-f8cce223a2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import ascii_lowercase\n",
    "from string import ascii_uppercase\n",
    "alphabet_list = list(ascii_lowercase) + list(ascii_uppercase) + list(\"ㆍ\") \n",
    "len(alphabet_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2eca3c4d-108c-4ae7-b1a5-2d71c49a1c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76695it [04:49, 265.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "76540"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Corpus Load\n",
    "# remove_set ={'0','1','2','3','4','5','6','7','8','9','10','할',\"위한\"}\n",
    "porter_stemmer = nltk.PorterStemmer().stem\n",
    "corpus = tp.utils.Corpus(\n",
    "    tokenizer=tp.utils.SimpleTokenizer(porter_stemmer),\n",
    "    stopwords= alphabet_list\n",
    ")\n",
    "#corpus.process(data_feeder(DATA_DIR+train_type+'.txt'))\n",
    "corpus.process(data_feeder(DATA_DIR+dtm_txt+'.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c77dae31-dbd0-4d4d-9d5f-465b4bdb7996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "워드네트워크를 만들 데이터를 입력하세요(Default: 엔터키):  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Default 워드네트워크 데이터를 불러옵니다.\n"
     ]
    }
   ],
   "source": [
    "wd_network_dtm=input(\"워드네트워크를 만들 데이터를 입력하세요(Default: 엔터키): \")\n",
    "if wd_network_dtm=='':\n",
    "    print(\"\\nDefault 워드네트워크 데이터를 불러옵니다.\")\n",
    "    wd_network_dtm= pd.read_csv(\"./data/Default/NTIS/DTM/wd_network_dtm_\"+str(num_topics) + \".csv\",encoding=\"cp949\",index_col=0)\n",
    "\n",
    "else:\n",
    "    print(\"\\n%s 에 워드네트워크 데이터를 불러옵니다.\"%(wd_network_dtm))\n",
    "    wd_network_dtm= pd.read_csv(\"./data/LDA/\"+data_ver+\"/\" + wd_network + \".csv\",encoding=\"cp949\",index_col=0)\n",
    "#    wd_network_dtm_41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8744de85-ef5e-4e68-a1db-a7515b70e33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>timepoint</th>\n",
       "      <th>mdl.docs</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Topic_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>연구 의 최종 목표 제조 복합 기능성 나노구조 광동역 치료 광간섭 단층촬영 생검 기...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;tomotopy.Document with words=\"연구 의 최종 목표 제조 복...</td>\n",
       "      <td>34</td>\n",
       "      <td>0.088473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>포자 피막 잉크젯 프린팅 장비 프린팅 기반 포자 피막 프린팅 공정 기 적합성 평가 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;tomotopy.Document with words=\"포자 피막 잉크젯 프린팅 장...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.387090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>감귤 잿빛곰팡이병 등 병해충 종 우수 방제 약제 선발 감귤 잿빛곰팡이병 감귤 귤굴나...</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;tomotopy.Document with words=\"감귤 잿빛곰팡이병 등 병해충...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.317911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>초저출산 시 대의 미래 인적자원 영유 아의 건강 관심 과 투 평생 건 강의 기반 영...</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;tomotopy.Document with words=\"초저출산 시 대의 미래 인적...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.157602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>내년 은 칼 맑스 None 지 이념적 찬반 대립 의미 의미 맑스 가 근대 정치 및 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;tomotopy.Document with words=\"내년 은 칼 맑스 지 이념적...</td>\n",
       "      <td>29</td>\n",
       "      <td>0.483182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76535</th>\n",
       "      <td>None None 성과 우수 특허 글로벌 기술이전 사업화 추진 None None 성...</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;tomotopy.Document with words=\"성과 우수 특허 글로벌 기술...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.140934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76536</th>\n",
       "      <td>결핵 유병 자 발생 자 사망 자의 도출 결핵 질병부담 결핵 검진 및 추가 검사 및 ...</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;tomotopy.Document with words=\"결핵 유병 자 발생 자 사망...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.297331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76537</th>\n",
       "      <td>최종목 표 암 미세환경 내 면역세포 면역 치료 예후 이의 작용기전 규명 세부 목표 ...</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;tomotopy.Document with words=\"최종목 표 암 미세환경 내 ...</td>\n",
       "      <td>27</td>\n",
       "      <td>0.362537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76538</th>\n",
       "      <td>조선족 중년여성 집단 의 건강형평성 제고 접근 앱 기반 건강증진 프로그램 을 개발 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;tomotopy.Document with words=\"조선족 중년여성 집단 의 건...</td>\n",
       "      <td>29</td>\n",
       "      <td>0.390675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76539</th>\n",
       "      <td>최종목 표 스마트 온실 용 전전 력 경량 다중센서 시스템 의 개발 및 실증 멀티센서...</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;tomotopy.Document with words=\"최종목 표 스마트 온실 용 ...</td>\n",
       "      <td>39</td>\n",
       "      <td>0.244334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76540 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  corpus  timepoint  \\\n",
       "0      연구 의 최종 목표 제조 복합 기능성 나노구조 광동역 치료 광간섭 단층촬영 생검 기...          1   \n",
       "1      포자 피막 잉크젯 프린팅 장비 프린팅 기반 포자 피막 프린팅 공정 기 적합성 평가 ...          1   \n",
       "2      감귤 잿빛곰팡이병 등 병해충 종 우수 방제 약제 선발 감귤 잿빛곰팡이병 감귤 귤굴나...          3   \n",
       "3      초저출산 시 대의 미래 인적자원 영유 아의 건강 관심 과 투 평생 건 강의 기반 영...          2   \n",
       "4      내년 은 칼 맑스 None 지 이념적 찬반 대립 의미 의미 맑스 가 근대 정치 및 ...          0   \n",
       "...                                                  ...        ...   \n",
       "76535  None None 성과 우수 특허 글로벌 기술이전 사업화 추진 None None 성...          3   \n",
       "76536  결핵 유병 자 발생 자 사망 자의 도출 결핵 질병부담 결핵 검진 및 추가 검사 및 ...          3   \n",
       "76537  최종목 표 암 미세환경 내 면역세포 면역 치료 예후 이의 작용기전 규명 세부 목표 ...          4   \n",
       "76538  조선족 중년여성 집단 의 건강형평성 제고 접근 앱 기반 건강증진 프로그램 을 개발 ...          0   \n",
       "76539  최종목 표 스마트 온실 용 전전 력 경량 다중센서 시스템 의 개발 및 실증 멀티센서...          4   \n",
       "\n",
       "                                                mdl.docs  Topic  Topic_prob  \n",
       "0      <tomotopy.Document with words=\"연구 의 최종 목표 제조 복...     34    0.088473  \n",
       "1      <tomotopy.Document with words=\"포자 피막 잉크젯 프린팅 장...      8    0.387090  \n",
       "2      <tomotopy.Document with words=\"감귤 잿빛곰팡이병 등 병해충...     25    0.317911  \n",
       "3      <tomotopy.Document with words=\"초저출산 시 대의 미래 인적...     26    0.157602  \n",
       "4      <tomotopy.Document with words=\"내년 은 칼 맑스 지 이념적...     29    0.483182  \n",
       "...                                                  ...    ...         ...  \n",
       "76535  <tomotopy.Document with words=\"성과 우수 특허 글로벌 기술...     24    0.140934  \n",
       "76536  <tomotopy.Document with words=\"결핵 유병 자 발생 자 사망...      7    0.297331  \n",
       "76537  <tomotopy.Document with words=\"최종목 표 암 미세환경 내 ...     27    0.362537  \n",
       "76538  <tomotopy.Document with words=\"조선족 중년여성 집단 의 건...     29    0.390675  \n",
       "76539  <tomotopy.Document with words=\"최종목 표 스마트 온실 용 ...     39    0.244334  \n",
       "\n",
       "[76540 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd_network_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc1cfda-5150-4529-b880-62ade4087601",
   "metadata": {},
   "source": [
    "# 단어 네트워크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76b1eedb-84cb-4e2d-b71b-bfd9ad2d2051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "분석하고 싶은 토픽 번호(1~41)를 입력하십시오: 0\n",
      "분석하고 싶은 timepoint(0~4)를 입력하십시오 ex)2017:0 : 4\n"
     ]
    }
   ],
   "source": [
    "topic_num=int(input(\"분석하고 싶은 토픽 번호(1~41)를 입력하십시오:\"))\n",
    "timepoint=int(input(\"분석하고 싶은 timepoint(0~4)를 입력하십시오 ex)2017:0 :\"))\n",
    "if timepoint == 0:\n",
    "    wd_network  = wd_network_dtm[wd_network_dtm[\"timepoint\"]==0]\n",
    "elif timepoint == 1:\n",
    "    wd_network  = wd_network_dtm[wd_network_dtm[\"timepoint\"]==1]\n",
    "elif timepoint == 2:\n",
    "    wd_network  = wd_network_dtm[wd_network_dtm[\"timepoint\"]==2]\n",
    "elif timepoint == 3:\n",
    "    wd_network  = wd_network_dtm[wd_network_dtm[\"timepoint\"]==3]\n",
    "elif timepoint == 4:\n",
    "    wd_network  = wd_network_dtm[wd_network_dtm[\"timepoint\"]==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65d45e5-8eb1-4d71-91b5-728a1e074d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wd_network = pd.DataFrame(index=range(len(corpus)),columns=[\"corpus\",\"timepoint\",\"mdl.docs\",\"Topic\",\"Topic_prob\"])\n",
    "\n",
    "# for i in tqdm(range(len(corpus))):\n",
    "#     wd_network.iloc[i][0] =  ' '.join(map(str, corpus[i]))\n",
    "\n",
    "# for u  in tqdm(range(len(corpus))):\n",
    "#     wd_network.iloc[u][1] = corpus[u].timepoint\n",
    "    \n",
    "# for j in tqdm(range(len(mdl.docs))):\n",
    "#     wd_network.iloc[j][2] = mdl.docs[j]\n",
    "\n",
    "# for z in tqdm(range(len(mdl.docs))):\n",
    "#     wd_network.iloc[z][3] = mdl.docs[z].get_topics(top_n=mdl.k)[0][0] + 1\n",
    "\n",
    "# for c in tqdm(range(len(mdl.docs))):\n",
    "#     wd_network.iloc[c][4] = mdl.docs[c].get_topics(top_n=mdl.k)[0][1]\n",
    "\n",
    "# wd_network_dmt = wd_network.copy()\n",
    "\n",
    "# wd_network_dtm.to_csv(\"./data/Default/NTIS/DTM/wd_network_dtm_\"+str(num_topics)+\".csv\",encoding=\"cp949\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77136d33-3a60-4c05-a660-b7c0f26594b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 토픽 별 상위 1000개 데이터를 이용한 사전 생성 \n",
    "using_word= []\n",
    "for i in range(500):\n",
    "    using_word.append(mdl.get_topic_words(topic_num-1,top_n=500,timepoint=timepoint)[i][0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fb1dbc-3e41-464c-99a3-df0d0d344216",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "if len(wd_network[wd_network[\"Topic\"]==topic_num].sort_values(\"Topic_prob\",ascending=False)) < 100:\n",
    "    a = len(wd_network[wd_network[\"Topic\"]==topic_num].sort_values(\"Topic_prob\",ascending=False))\n",
    "else :\n",
    "    a = 100 \n",
    "for i in tqdm(range(a)):\n",
    "    temp = wd_network[wd_network[\"Topic\"]==topic_num].sort_values(\"Topic_prob\",ascending=False).iloc[i][0]\n",
    "    temp2 = []\n",
    "    for j in (temp.split(\" \")):\n",
    "        if j in using_word:\n",
    "            temp2.append(j)\n",
    "        else:\n",
    "            continue\n",
    "    count = {}\n",
    "    for c,a in tqdm(enumerate(temp2)):  # i는 숫자 a는 1행 \n",
    "        for b in temp2[c+1:]:\n",
    "            if a>b:\n",
    "                count[b,a] = count.get((b,a),0)+1\n",
    "            else:\n",
    "                count[a,b] = count.get((a,b),0)+1\n",
    "    word_df = pd.DataFrame.from_dict(count,orient=\"index\")  \n",
    "    df = pd.concat([df,word_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a836942e-f7d7-4619-a3e0-b33a1f0b8050",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df[1] = pd.DataFrame(df[\"index\"].tolist())[0]\n",
    "df[2] = pd.DataFrame(df[\"index\"].tolist())[1]\n",
    "df = df[df[1]!=df[2]]\n",
    "df= pd.DataFrame(df.groupby(\"index\")[0].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfacb80-1b93-47c5-83bb-1a32132705e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = []\n",
    "for i in range(len(df)):\n",
    "    list1.append([df.index[i][0],df.index[i][1],df[0][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b11d037-8537-4a91-b726-e8c7b30d7475",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(list1,columns=[\"term1\",\"term2\",\"freq\"])\n",
    "df3 = df2.sort_values(by=[\"freq\"],ascending=False)\n",
    "df3 = df3.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7117e0f5-01db-4c7c-95e3-c89be3e16653",
   "metadata": {},
   "outputs": [],
   "source": [
    "i =1\n",
    "while len((np.where(df3[\"freq\"]>=i))[0])>100:\n",
    "    i +=1\n",
    "freq_num=i\n",
    "print(freq_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7336ef8-960f-4391-b931-8501755aae9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_centrality = nx.Graph()\n",
    "for i in tqdm(range(len((np.where(df3[\"freq\"]>=freq_num))[0]))):\n",
    "    G_centrality.add_edge(df3[\"term1\"][i],df3[\"term2\"][i],weight=int(df3[\"freq\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3279ca-b369-411b-8c0e-a1fa8a06dca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dgr = nx.degree_centrality(G_centrality)      #연결 중심성\n",
    "btw = nx.betweenness_centrality(G_centrality) #매개 중심성\n",
    "cls = nx.closeness_centrality(G_centrality)   #근접 중심성\n",
    "egv = nx.eigenvector_centrality(G_centrality) #고유벡터 중심성\n",
    "pgr = nx.pagerank(G_centrality) #페이지랭크 안됨 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd29539-f437-4fd5-bf1f-5afb50f8f261",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dgr = sorted(dgr.items(), key=operator.itemgetter(1), reverse=True)\n",
    "sorted_btw = sorted(btw.items(), key=operator.itemgetter(1), reverse=True)\n",
    "sorted_cls = sorted(cls.items(), key=operator.itemgetter(1), reverse=True)\n",
    "sorted_egv = sorted(egv.items(), key=operator.itemgetter(1), reverse=True)\n",
    "sorted_pgr = sorted(pgr.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0ae1c4-d93a-462c-a755-e00908b9fff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "G= nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc13c93-4027-416b-b762-6e8879f88171",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(sorted_pgr))):\n",
    "    G.add_node(sorted_pgr[i][0],nodesize=sorted_dgr[i][1])\n",
    "\n",
    "for i in tqdm(range(len((np.where(df3[\"freq\"]>=freq_num))[0]))):\n",
    "    G.add_weighted_edges_from([(df3[\"term1\"][i],df3[\"term2\"][i],int(df3[\"freq\"][i]))])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37de8ee0-9fd6-4b3e-8347-c65fe1cafa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [G.nodes[node][\"nodesize\"]*2000 for node in G]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d05fe04-640c-4f49-a08a-3aebb8043f0f",
   "metadata": {},
   "source": [
    "## 텍스트 네트워크 폰트 설정 및 그래프 그리기\n",
    "#### <에러나면 아래로 가서 패키지 실행 후 올라오기>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2e5ba6-5327-489d-83c1-807a41e32354",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 마이너스 폰트 깨지는 문제에 대한 대처\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "font_fname = \"C:\\\\Windows\\\\Fonts\\\\NanumGothicCoding-bold.ttf\"\n",
    "fontprop = fm.FontProperties(fname=font_fname,size=10).get_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1107df18-259a-49ea-a9e0-73c4c28e8869",
   "metadata": {},
   "outputs": [],
   "source": [
    "options={\n",
    "    \"edge_color\":'#FFDEA2',\n",
    "    \"width\":1,\n",
    "    \"with_labels\":True,\n",
    "    \"font_weight\":\"bold\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c235cb-532f-42ca-965b-fcd1f102ab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos=nx.fruchterman_reingold_layout(G)\n",
    "#pos=nx.spectral_layout(G)\n",
    "#pos=nx.random_layout(G)\n",
    "#pos=nx.shell_layout(G)\n",
    "#pos=nx.circular_layout(G)\n",
    "#pos=nx.spring_layout(G,k=3.5,iterations=100)\n",
    "#pos=nx.kamada_kawai_layout(G)\n",
    "\n",
    "plt.figure(figsize=(16,8)); \n",
    "nx.draw_networkx(G,node_size=sizes,pos=nx.kamada_kawai_layout(G),**options,font_family=fontprop)\n",
    "ax = plt.gca()\n",
    "ax.collections[0].set_edgecolor(\"#555555\")\n",
    "#plt.savefig(\"temp.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23c8853-08e5-4f86-af87-364e990c18c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos=nx.fruchterman_reingold_layout(G)\n",
    "#pos=nx.spectral_layout(G)\n",
    "#pos=nx.random_layout(G)\n",
    "#pos=nx.shell_layout(G)\n",
    "#pos=nx.circular_layout(G)\n",
    "#pos=nx.spring_layout(G,k=3.5,iterations=100)\n",
    "#pos=nx.kamada_kawai_layout(G)\n",
    "\n",
    "plt.figure(figsize=(16,8)); \n",
    "nx.draw_networkx(G,node_size=sizes,pos=nx.spring_layout(G,k=3.5,iterations=100),**options,font_family=fontprop)\n",
    "ax = plt.gca()\n",
    "ax.collections[0].set_edgecolor(\"#555555\")\n",
    "# plt.savefig(\"C:\\\\Users\\\\KISDI\\\\LDA\\\\html\\\\LDA\\\\NTIS\\\\NTIS_WD_NETWORK_TOPIC_\"+ str(topic_num) + \".png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954b810d-a8f4-42a5-8961-b36071e7d660",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"** degree **\")\n",
    "for x in range(len(G)):\n",
    "    print(sorted_dgr[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8c63d2-dd03-4632-9d8e-d4e378d9d641",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"** betweenness **\")\n",
    "for x in range(len(G)):\n",
    "    print(sorted_btw[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb292d5-5b3a-443e-b051-966b4639235c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"** closeness **\")\n",
    "for x in range(len(G)):\n",
    "    print(sorted_cls[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662e2b49-3f78-4804-ba0c-d503b03c193a",
   "metadata": {},
   "source": [
    "## 최초 1회 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a69028-3712-4526-95ec-c1dec5ab1b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('버전: ', mpl.__version__)\n",
    "print ('설치 위치: ', mpl.__file__)\n",
    "print ('설정 위치: ', mpl.get_configdir())\n",
    "print ('캐시 위치: ', mpl.get_cachedir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc183ad3-895c-4425-af70-866c5ffcc6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('설정파일 위치: ', mpl.matplotlib_fname())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693d5e0e-1cc8-46be-98e2-5b91acc618dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(f.name, f.fname) for f in fm.fontManager.ttflist if 'Nanum' in f.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b9e4e6-3f51-45c7-ad60-38951cefd9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"font\", family=\"NanumGothicCoding\")\n",
    "print(plt.rcParams[\"font.family\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac53ca6-1970-4bf7-9220-e5ec5267de58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#단어끼리 서로 빈도를 세는 데이터셋을 만들었을 때 Gaphi로 시각화하는 것 전단계: graphml 확장자 형식으로 만들기\n",
    "class MakeGraphml:\n",
    "    def make_graphml(self, pair_file, graphml_file):\n",
    "        out = open(graphml_file, 'w', encoding = 'utf-8')\n",
    "        entity = []\n",
    "        e_dict = {}\n",
    "        count = []\n",
    "        for i in range(len(pair_file)):\n",
    "            e1 = pair_file.iloc[i,0]\n",
    "            e2 = pair_file.iloc[i,1]\n",
    "            #frq = ((word_dict[e1], word_dict[e2]),  pair.split('\\t')[2])\n",
    "            frq = ((e1, e2), pair_file.iloc[i,2])\n",
    "            if frq not in count: count.append(frq)   # ((a, b), frq)\n",
    "            if e1 not in entity: entity.append(e1)\n",
    "            if e2 not in entity: entity.append(e2)\n",
    "        print('# terms: %s'% len(entity))\n",
    "        #create e_dict {entity: id} from entity\n",
    "        for i, w in enumerate(entity):\n",
    "            e_dict[w] = i + 1 # {word: id}\n",
    "        out.write(\n",
    "            \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?><graphml xmlns=\\\"http://graphml.graphdrawing.org/xmlns\\\" xmlns:xsi=\\\"http://www.w3.org/2001/XMLSchema-instance\\\" xsi:schemaLocation=\\\"http://graphml.graphdrawing.org/xmlnshttp://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd\\\">\" +\n",
    "            \"<key id=\\\"d1\\\" for=\\\"edge\\\" attr.name=\\\"weight\\\" attr.type=\\\"double\\\"/>\" +\n",
    "            \"<key id=\\\"d0\\\" for=\\\"node\\\" attr.name=\\\"label\\\" attr.type=\\\"string\\\"/>\" +\n",
    "            \"<graph id=\\\"Entity\\\" edgedefault=\\\"undirected\\\">\" + \"\\n\")\n",
    "        # nodes\n",
    "        for i in entity:\n",
    "            out.write(\"<node id=\\\"\" + str(e_dict[i]) +\"\\\">\" + \"\\n\")\n",
    "            out.write(\"<data key=\\\"d0\\\">\" + i + \"</data>\" + \"\\n\")\n",
    "            out.write(\"</node>\")\n",
    "        # edges\n",
    "        for y in range(len(count)):\n",
    "            out.write(\"<edge source=\\\"\" + str(e_dict[count[y][0][0]]) + \"\\\" target=\\\"\" + str(e_dict[count[y][0][1]]) + \"\\\">\" + \"\\n\")\n",
    "            out.write(\"<data key=\\\"d1\\\">\" + str(count[y][1]) + \"</data>\" + \"\\n\")\n",
    "            #out.write(\"<edge source=\\\"\" + str(count[y][0][0]) + \"\\\" target=\\\"\" + str(count[y][0][1]) +\"\\\">\"+\"\\n\")\n",
    "            #out.write(\"<data key=\\\"d1\\\">\" + str(count[y][1]) +\"</data>\"+\"\\n\")\n",
    "            out.write(\"</edge>\")\n",
    "        out.write(\"</graph> </graphml>\")\n",
    "        print('now you can see %s' % graphml_file)\n",
    "        #pairs.close()\n",
    "        out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af759e96-6bd8-481b-a748-01c8831bd4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gm = MakeGraphml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9491463b-a699-47b7-8764-c614616656a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphml_file = 'wd_network.graphml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1437bdda-16f3-44d2-b177-acaf94df35ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "gm.make_graphml(df3.iloc[0:len((np.where(df3[\"freq\"]>=5))[0]),:], graphml_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954cf1ca-91fb-4adb-babd-2100dcce8012",
   "metadata": {},
   "source": [
    "# 자동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb168ab-f949-416f-9459-353c0af81d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_range = input(\"사용년도의 범위를 입력하시오 ex)2017~2021:5 :\")\n",
    "topic_len = input(\"토픽의 개수를 입력하시오:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69970ab2-f20c-4700-9816-9bf7a12be98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_network_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7164ebc-3216-4593-9967-acf5af3c43e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for timepoint in tqdm(range(int(year_range))):\n",
    "\n",
    "    if timepoint == 0:\n",
    "        wd_network  = wd_network_dtm[wd_network_dtm[\"timepoint\"]==0]\n",
    "    elif timepoint == 1:\n",
    "        wd_network  = wd_network_dtm[wd_network_dtm[\"timepoint\"]==1]\n",
    "    elif timepoint == 2:\n",
    "        wd_network  = wd_network_dtm[wd_network_dtm[\"timepoint\"]==2]\n",
    "    elif timepoint == 3:\n",
    "        wd_network  = wd_network_dtm[wd_network_dtm[\"timepoint\"]==3]\n",
    "    elif timepoint == 4:\n",
    "        wd_network  = wd_network_dtm[wd_network_dtm[\"timepoint\"]==4]\n",
    "        \n",
    "\n",
    "    for topic_num in range(int(topic_len)):\n",
    "        using_word= []\n",
    "        for i in range(500):\n",
    "            using_word.append(mdl.get_topic_words(topic_num,top_n=500,timepoint=timepoint)[i][0]) \n",
    "            \n",
    "        df = pd.DataFrame()\n",
    "        if len(wd_network[wd_network[\"Topic\"]==topic_num+1].sort_values(\"Topic_prob\",ascending=False)) < 100:\n",
    "            a = len(wd_network[wd_network[\"Topic\"]==topic_num+1].sort_values(\"Topic_prob\",ascending=False))\n",
    "        else :\n",
    "            a = 100 \n",
    "        for i in range(a):\n",
    "            temp = wd_network[wd_network[\"Topic\"]==topic_num+1].sort_values(\"Topic_prob\",ascending=False).iloc[i][0]\n",
    "            temp2 = []\n",
    "            for j in (temp.split(\" \")):\n",
    "                if j in using_word:\n",
    "                    temp2.append(j)\n",
    "                else:\n",
    "                    continue\n",
    "            count = {}\n",
    "            for c,a in enumerate(temp2):  # i는 숫자 a는 1행 \n",
    "                for b in temp2[c+1:]:\n",
    "                    if a>b:\n",
    "                        count[b,a] = count.get((b,a),0)+1\n",
    "                    else:\n",
    "                        count[a,b] = count.get((a,b),0)+1\n",
    "            word_df = pd.DataFrame.from_dict(count,orient=\"index\")  \n",
    "            df = pd.concat([df,word_df])\n",
    "            \n",
    "        df.reset_index(inplace=True)\n",
    "        df[1] = pd.DataFrame(df[\"index\"].tolist())[0]\n",
    "        df[2] = pd.DataFrame(df[\"index\"].tolist())[1]\n",
    "        df = df[df[1]!=df[2]]\n",
    "        df= pd.DataFrame(df.groupby(\"index\")[0].sum())\n",
    "        \n",
    "        list1 = []\n",
    "        for i in range(len(df)):\n",
    "            list1.append([df.index[i][0],df.index[i][1],df[0][i]])\n",
    "            \n",
    "        df2 = pd.DataFrame(list1,columns=[\"term1\",\"term2\",\"freq\"])\n",
    "        df3 = df2.sort_values(by=[\"freq\"],ascending=False)\n",
    "        df3 = df3.reset_index(drop=True)\n",
    "        \n",
    "        i =1\n",
    "        while len((np.where(df3[\"freq\"]>=i))[0])>100:\n",
    "            i +=1\n",
    "        freq_num=i\n",
    "        \n",
    "        G_centrality = nx.Graph()\n",
    "        for i in range(len((np.where(df3[\"freq\"]>=freq_num))[0])):\n",
    "            G_centrality.add_edge(df3[\"term1\"][i],df3[\"term2\"][i],weight=int(df3[\"freq\"][i]))\n",
    "            \n",
    "        dgr = nx.degree_centrality(G_centrality)      #연결 중심성\n",
    "        btw = nx.betweenness_centrality(G_centrality) #매개 중심성\n",
    "\n",
    "        cls = nx.closeness_centrality(G_centrality)   #근접 중심성\n",
    "        egv = nx.eigenvector_centrality(G_centrality) #고유벡터 중심성\n",
    "        pgr = nx.pagerank(G_centrality) #페이지랭크 안됨 \n",
    "        \n",
    "        sorted_dgr = sorted(dgr.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        sorted_btw = sorted(btw.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        sorted_cls = sorted(cls.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        sorted_egv = sorted(egv.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        sorted_pgr = sorted(pgr.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        \n",
    "        G= nx.Graph()\n",
    "        \n",
    "        for i in range(len(sorted_pgr)):\n",
    "            G.add_node(sorted_pgr[i][0],nodesize=sorted_dgr[i][1])\n",
    "        for i in range(len((np.where(df3[\"freq\"]>=freq_num))[0])):\n",
    "            G.add_weighted_edges_from([(df3[\"term1\"][i],df3[\"term2\"][i],int(df3[\"freq\"][i]))])\n",
    "        \n",
    "        sizes = [G.nodes[node][\"nodesize\"]*2000 for node in G]\n",
    "        \n",
    "        ## 마이너스 폰트 깨지는 문제에 대한 대처\n",
    "        mpl.rcParams['axes.unicode_minus'] = False\n",
    "        font_fname = \"C:\\\\Windows\\\\Fonts\\\\NanumGothicCoding-bold.ttf\"\n",
    "        fontprop = fm.FontProperties(fname=font_fname,size=10).get_name()\n",
    "        \n",
    "        options={\n",
    "            \"edge_color\":'#FFDEA2',\n",
    "            \"width\":1,\n",
    "            \"with_labels\":True,\n",
    "            \"font_weight\":\"bold\",\n",
    "        }\n",
    "        \n",
    "        plt.figure(figsize=(16,8)); \n",
    "        nx.draw_networkx(G,node_size=sizes,pos=nx.kamada_kawai_layout(G),**options,font_family=fontprop)\n",
    "        ax = plt.gca()\n",
    "        ax.collections[0].set_edgecolor(\"#555555\")\n",
    "        \n",
    "        plt.savefig(\"C:\\\\Users\\\\newcomer02\\\\NTIS_Project\\\\data\\\\Default\\\\NTIS\\\\DTM\\\\Topic_\"+ str(timepoint+2017) + \"\\\\Topic\" + str(topic_num+1) +\".png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b007c7da-5f0f-48ed-a15a-7452ba32afab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mecab",
   "language": "python",
   "name": "mecab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
